{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 937 triples to http://localhost:9999/blazegraph/sparql.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from rdflib import Graph, Namespace, URIRef, Literal, RDF, RDFS, OWL, XSD\n",
    "from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore\n",
    "\n",
    "def create_perspectivisation_graph(csv_file, endpoint_url):\n",
    "    \"\"\"\n",
    "    Reads the CSV of LGBTQ+ teen TV characters and maps each row to your\n",
    "    Perspectivisation ontology. Then uploads to a SPARQL endpoint (e.g. Blazegraph).\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) SPARQL endpoint\n",
    "    #    Example: http://localhost:9999/blazegraph/sparql\n",
    "    endpoint = \"http://localhost:9999/blazegraph/sparql\"\n",
    "\n",
    "    # 2) Ontology namespace (perspectivisation.owl) plus an example namespace for new individuals\n",
    "    PERSPECT = Namespace(\"http://www.ontologydesignpatterns.org/ont/persp/perspectivisation.owl#\")\n",
    "    EX       = Namespace(\"http://example.org/resource/\")\n",
    "\n",
    "    # 3) Create a new RDF graph\n",
    "    g = Graph()\n",
    "\n",
    "    # 4) Bind prefixes (for nicer serialization)\n",
    "    g.bind(\"persp\", PERSPECT)\n",
    "    g.bind(\"ex\",    EX)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # (Optional) Re-declare some classes and properties if your store is NOT\n",
    "    # already loaded with your ontology. If it is, you can remove these lines.\n",
    "    # --------------------------------------------------------------------------\n",
    "    g.add((PERSPECT.FairRepresentation,    RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.UnfairRepresentation,  RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.DetailedPortrayal,     RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.SuperficialPortrayal,  RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.AuthenticCharacterization, RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.CharacterTransformation, RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.DynamicRole, RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.StaticRole,  RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.StereotypicalCharacterization, RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.PlotResolution, RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.IdeologicalChallenge, RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.ProfitAndMassAppeal,  RDF.type, OWL.Class))\n",
    "\n",
    "    # Classes from the ontology's \"roles\"\n",
    "    g.add((PERSPECT.Attitude,    RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.Lens,        RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.Cut,         RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.Eventuality, RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.Conceptualizer, RDF.type, OWL.Class))\n",
    "    g.add((PERSPECT.Perspectivisation, RDF.type, OWL.Class))\n",
    "\n",
    "    # Punned properties\n",
    "    g.add((PERSPECT.Attitude,    RDF.type, OWL.ObjectProperty))\n",
    "    g.add((PERSPECT.Lens,        RDF.type, OWL.ObjectProperty))\n",
    "    g.add((PERSPECT.Cut,         RDF.type, OWL.ObjectProperty))\n",
    "    g.add((PERSPECT.Eventuality, RDF.type, OWL.ObjectProperty))\n",
    "    g.add((PERSPECT.Conceptualiser, RDF.type, OWL.ObjectProperty))\n",
    "    # etc. if desired\n",
    "\n",
    "    # For storing textual columns, define some data properties in our EX namespace\n",
    "    # (You can also use rdfs:comment or define them in your ontology if you prefer.)\n",
    "    hasShowTitle    = EX.hasShowTitle\n",
    "    hasJustification= EX.hasJustification\n",
    "    hasImpact       = EX.hasImpact\n",
    "    hasAffirmation  = EX.hasAffirmation\n",
    "    hasNormalization= EX.hasNormalization\n",
    "    hasGBF          = EX.hasGayBestFriend\n",
    "    hasTragicTrope  = EX.hasTragicTrope\n",
    "    hasTokenism     = EX.hasTokenism\n",
    "    hasPlotDesc     = EX.hasPlotResolutionDesc\n",
    "\n",
    "    for dp in [hasShowTitle, hasJustification, hasImpact, hasAffirmation,\n",
    "               hasNormalization, hasGBF, hasTragicTrope, hasTokenism, hasPlotDesc]:\n",
    "        g.add((dp, RDF.type, OWL.DatatypeProperty))\n",
    "        g.add((dp, RDFS.range, URIRef(XSD.string)))  # store them as xsd:string\n",
    "\n",
    "    # 5) Open the CSV and process each row\n",
    "    with open(\"new dataset(Foglio1).csv\", mode='r', encoding='utf-8', errors=\"replace\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        \n",
    "        row_num = 0\n",
    "        for row in reader:\n",
    "            row_num += 1\n",
    "\n",
    "            # ---------------------------\n",
    "            # Extract columns from CSV\n",
    "            # ---------------------------\n",
    "            char_name     = row[\"Character Name\"].strip()\n",
    "            show_title    = row[\"Show Title\"].strip()\n",
    "            rep_type      = row[\"Representation Type\"].strip()  # \"Fair Representation\" / \"Unfair Representation\"\n",
    "            justification = row[\"Justification for Classification\"].strip()\n",
    "            impact        = row[\"LGBTQ Community Impact\"].strip()\n",
    "            portrayal     = row[\"Portrayal\"].strip()            # \"Detailed\" / \"Superficial\"\n",
    "            auth_char     = row[\"Authentic Characterization\"].strip()  # \"Yes\" / \"No\"\n",
    "            affirm_id     = row[\"Affirmation of Identity\"].strip()      # \"Yes\"/\"No\"\n",
    "            normalize_rel = row[\"Normalization of Relationship\"].strip()# \"Yes\"/\"No\"\n",
    "            dynamic_role  = row[\"Dynamic Role\"].strip()                 # \"Yes\"/\"No\"\n",
    "            static_role   = row[\"Static Role\"].strip()                  # \"Yes\"/\"No\"\n",
    "            stereo_char   = row[\"Stereotypical Characterization\"].strip() # \"Yes\"/\"No\"\n",
    "            gay_bf        = row[\"Gay Best Friend\"].strip()              # \"Yes\"/\"No\"\n",
    "            tragic_trope  = row[\"Tragic Trope\"].strip()                 # \"Yes\"/\"No\"\n",
    "            tokenism      = row[\"Tokenism\"].strip()                     # \"Yes\"/\"No\"\n",
    "            char_trans    = row[\"Character Transformation\"].strip()     # possibly text\n",
    "            plot_res      = row[\"Plot Resolution\"].strip()              # possibly text\n",
    "            lens_orient   = row[\"Lens Orientation\"].strip()             # \"Ideological Challenge\" / \"Profit and Mass Appeal\"\n",
    "\n",
    "            # ------------------------------------------\n",
    "            # Create a main Perspectivisation for this row\n",
    "            # plus role individuals (Cut, Lens, Attitude, etc.)\n",
    "            # ------------------------------------------\n",
    "            # e.g., ex:persp_1, ex:cut_1, ex:lens_1, ex:att_1, ...\n",
    "            persp_uri = EX[f\"Perspectivisation_{row_num}\"]\n",
    "            cut_uri   = EX[f\"Cut_{row_num}\"]\n",
    "            lens_uri  = EX[f\"Lens_{row_num}\"]\n",
    "            att_uri   = EX[f\"Attitude_{row_num}\"]\n",
    "            ev_uri    = EX[f\"Eventuality_{row_num}\"]\n",
    "            con_uri   = EX[f\"Conceptualizer_{row_num}\"]\n",
    "            # (We wonâ€™t create a \"Background\" because CSV has no background column, \n",
    "            #  but you could if needed.)\n",
    "\n",
    "            # Type them according to the ontology roles\n",
    "            g.add((persp_uri, RDF.type, PERSPECT.Perspectivisation))\n",
    "            g.add((cut_uri,   RDF.type, PERSPECT.Cut))\n",
    "            g.add((lens_uri,  RDF.type, PERSPECT.Lens))\n",
    "            g.add((att_uri,   RDF.type, PERSPECT.Attitude))\n",
    "            g.add((ev_uri,    RDF.type, PERSPECT.Eventuality))\n",
    "            g.add((con_uri,   RDF.type, PERSPECT.Conceptualizer))\n",
    "\n",
    "            # Link them: Perspectivisation -> {Cut, Lens, Attitude, Eventuality, Conceptualiser}\n",
    "            g.add((persp_uri, PERSPECT.Cut,         cut_uri))\n",
    "            g.add((persp_uri, PERSPECT.Lens,        lens_uri))\n",
    "            g.add((persp_uri, PERSPECT.Attitude,    att_uri))\n",
    "            g.add((persp_uri, PERSPECT.Eventuality, ev_uri))\n",
    "            g.add((persp_uri, PERSPECT.Conceptualiser, con_uri))\n",
    "\n",
    "            # We also say that the Attitude is \"toward\" the Cut:\n",
    "            g.add((att_uri, PERSPECT.toward, cut_uri))\n",
    "\n",
    "            # ------------------------------------------\n",
    "            # Multi-type the CUT individual based on CSV\n",
    "            # e.g. if rep_type is \"Fair Representation\" => type :FairRepresentation\n",
    "            # ------------------------------------------\n",
    "            if rep_type.lower().startswith(\"fair\"):\n",
    "                g.add((cut_uri, RDF.type, PERSPECT.FairRepresentation))\n",
    "                # Optionally set \"accuracyOfRepresentation\" to \"High\"\n",
    "                # only if you want that property automatically:\n",
    "                g.add((cut_uri, PERSPECT.accuracyOfRepresentation, Literal(\"High\")))\n",
    "            else:\n",
    "                g.add((cut_uri, RDF.type, PERSPECT.UnfairRepresentation))\n",
    "                g.add((cut_uri, PERSPECT.accuracyOfRepresentation, Literal(\"Low\")))\n",
    "\n",
    "            # Portrayal => DetailedPortrayal or SuperficialPortrayal\n",
    "            if portrayal.lower() == \"detailed\":\n",
    "                g.add((cut_uri, RDF.type, PERSPECT.DetailedPortrayal))\n",
    "            else:\n",
    "                g.add((cut_uri, RDF.type, PERSPECT.SuperficialPortrayal))\n",
    "\n",
    "            # Authentic Characterization => if yes => add type\n",
    "            if auth_char.lower() == \"yes\":\n",
    "                g.add((cut_uri, RDF.type, PERSPECT.AuthenticCharacterization))\n",
    "\n",
    "            # Dynamic Role => if yes => add type\n",
    "            if dynamic_role.lower() == \"yes\":\n",
    "                g.add((cut_uri, RDF.type, PERSPECT.DynamicRole))\n",
    "\n",
    "            # Static Role => if yes => add type\n",
    "            if static_role.lower() == \"yes\":\n",
    "                g.add((cut_uri, RDF.type, PERSPECT.StaticRole))\n",
    "\n",
    "            # Stereotypical Characterization => if yes => add type\n",
    "            if stereo_char.lower() == \"yes\":\n",
    "                g.add((cut_uri, RDF.type, PERSPECT.StereotypicalCharacterization))\n",
    "\n",
    "            # Character Transformation => if not empty => type CharacterTransformation\n",
    "            if char_trans.strip():\n",
    "                g.add((cut_uri, RDF.type, PERSPECT.CharacterTransformation))\n",
    "\n",
    "            # Plot Resolution => if not empty => type PlotResolution\n",
    "            if plot_res.strip():\n",
    "                g.add((cut_uri, RDF.type, PERSPECT.PlotResolution))\n",
    "\n",
    "            # -----------------------------------------------------\n",
    "            # Lens orientation => type the LENS as IdeologicalChallenge or ProfitAndMassAppeal\n",
    "            # -----------------------------------------------------\n",
    "            if lens_orient.lower().startswith(\"ideological\"):\n",
    "                g.add((lens_uri, RDF.type, PERSPECT.IdeologicalChallenge))\n",
    "            else:\n",
    "                g.add((lens_uri, RDF.type, PERSPECT.ProfitAndMassAppeal))\n",
    "\n",
    "            # ------------------------------------------\n",
    "            # Store textual data (Character Name, Show, Justifications, etc.)\n",
    "            # on the \"Cut\" or a relevant node\n",
    "            # ------------------------------------------\n",
    "            # For clarity, letâ€™s store the character name and show title on the Cut\n",
    "            # as label + a custom property:\n",
    "            g.add((cut_uri, RDFS.label, Literal(char_name, datatype=XSD.string)))\n",
    "            g.add((cut_uri, hasShowTitle, Literal(show_title, datatype=XSD.string)))\n",
    "\n",
    "            # Justification for Classification => store as property\n",
    "            if justification:\n",
    "                g.add((cut_uri, hasJustification, Literal(justification, datatype=XSD.string)))\n",
    "\n",
    "            # LGBTQ Community Impact => store as property\n",
    "            if impact:\n",
    "                g.add((cut_uri, hasImpact, Literal(impact, datatype=XSD.string)))\n",
    "\n",
    "            # Affirmation of Identity => store as property\n",
    "            if affirm_id:\n",
    "                g.add((cut_uri, hasAffirmation, Literal(affirm_id, datatype=XSD.string)))\n",
    "\n",
    "            # Normalization of Relationship => store as property\n",
    "            if normalize_rel:\n",
    "                g.add((cut_uri, hasNormalization, Literal(normalize_rel, datatype=XSD.string)))\n",
    "\n",
    "            # Gay Best Friend => store as property\n",
    "            if gay_bf:\n",
    "                g.add((cut_uri, hasGBF, Literal(gay_bf, datatype=XSD.string)))\n",
    "\n",
    "            # Tragic Trope => store as property\n",
    "            if tragic_trope:\n",
    "                g.add((cut_uri, hasTragicTrope, Literal(tragic_trope, datatype=XSD.string)))\n",
    "\n",
    "            # Tokenism => store as property\n",
    "            if tokenism:\n",
    "                g.add((cut_uri, hasTokenism, Literal(tokenism, datatype=XSD.string)))\n",
    "\n",
    "            # Plot Resolution => store the text description\n",
    "            if plot_res:\n",
    "                g.add((cut_uri, hasPlotDesc, Literal(plot_res, datatype=XSD.string)))\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 6) Upload everything to the SPARQL endpoint\n",
    "    # --------------------------------------------------------------------------\n",
    "    store = SPARQLUpdateStore()\n",
    "    store.open((endpoint, endpoint))  # pass as (query, update)\n",
    "\n",
    "    for triple in g.triples((None, None, None)):\n",
    "        store.add(triple)\n",
    "\n",
    "    store.close()\n",
    "    print(f\"Uploaded {len(g)} triples to {endpoint}.\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Example usage\n",
    "# ------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace these with your actual CSV path and your SPARQL endpoint\n",
    "    csv_file_path = \"new dataset(Foglio1).csv\"  # CSV with the columns you provided\n",
    "    blazegraph_sparql_endpoint = \"http://localhost:9999/blazegraph/sparql\"\n",
    "\n",
    "    create_perspectivisation_graph(csv_file_path, blazegraph_sparql_endpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
